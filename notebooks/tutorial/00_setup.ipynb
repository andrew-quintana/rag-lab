{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RAGLab Tutorial: Setup and Environment Configuration\n\n**Welcome to RAGLab!** This notebook series will walk you through RAGLab's comprehensive RAG evaluation framework, including the new component registry system that enables comparative testing of multiple implementations.\n\n## What You'll Learn\n\nThis tutorial series covers:\n\n1. **Setup & Configuration** (this notebook) - Environment setup and component registry introduction\n2. **Ingest & Index** - Document chunking and FAISS indexing with component comparison\n3. **Retrieval Evaluation** - BEIR-style retrieval metrics across different implementations  \n4. **Agent Evaluation** - Complete RAG pipeline evaluation with LLM-as-Judge\n5. **Analysis & Comparison** - Results analysis and component performance comparison\n\n## RAGLab Overview\n\nRAGLab is a **local-first** RAG evaluation framework featuring:\n\n- **üèõÔ∏è Component Registry**: Compare multiple implementations side-by-side\n- **‚öñÔ∏è LLM-as-Judge**: Multi-stage evaluation with insurance risk semantics\n- **üìä BEIR Metrics**: Standard retrieval evaluation (Recall@K, Precision@K, nDCG@K)\n- **üîç Meta-Evaluation**: Judge reliability assessment and bias detection\n- **üìì Notebook-Driven**: Interactive development and analysis workflow\n- **üè† Local Storage**: No cloud dependencies, complete data ownership\n\n## Key Innovation: Component Registry\n\nRAGLab's registry system allows you to:\n- Register multiple implementations of each component type\n- Switch between implementations with simple name changes\n- Compare performance across different approaches\n- Test new implementations against established baselines\n\nLet's get started!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Basic imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import raglab modules\nfrom core.io import DataLoader, RunManager\nfrom core.interfaces import EvaluationExample, Query, Chunk\n\nprint(\"‚úÖ RAGLab modules imported successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system requirements\n",
    "try:\n",
    "    import faiss\n",
    "    print(f\"‚úÖ FAISS version: {faiss.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå FAISS not installed. Install with: pip install faiss-cpu\")\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "    print(\"‚úÖ YAML support available\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PyYAML not installed. Install with: pip install pyyaml\")\n",
    "\n",
    "# Check directory structure\n",
    "base_path = Path('..')\n",
    "required_dirs = ['data', 'artifacts', 'runs', 'src', 'docs']\n",
    "\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = base_path / dir_name\n",
    "    if dir_path.exists():\n",
    "        print(f\"‚úÖ {dir_name}/ directory exists\")\n",
    "    else:\n",
    "        print(f\"‚ùå {dir_name}/ directory missing\")\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  ‚Üí Created {dir_name}/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up your LLM and embedding providers here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LLM function (replace with your actual provider)\n",
    "def example_llm_function(prompt: str, temperature: float = 0.1, max_tokens: int = 500) -> str:\n",
    "    \"\"\"\n",
    "    Replace this with your actual LLM API call.\n",
    "    \n",
    "    Example providers:\n",
    "    - OpenAI: openai.ChatCompletion.create(...)\n",
    "    - Azure OpenAI: azure_openai.ChatCompletion.create(...)\n",
    "    - Anthropic: anthropic.messages.create(...)\n",
    "    \"\"\"\n",
    "    # This is a mock implementation\n",
    "    return f\"Mock LLM response to: {prompt[:50]}...\"\n",
    "\n",
    "# Example embedding function (replace with your actual provider) \n",
    "def example_embedding_function(texts: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Replace this with your actual embedding API call.\n",
    "    \n",
    "    Example providers:\n",
    "    - OpenAI: openai.embeddings.create(model=\"text-embedding-ada-002\", input=texts)\n",
    "    - Sentence Transformers: model.encode(texts)\n",
    "    - Cohere: co.embed(texts=texts, model=\"embed-english-v3.0\")\n",
    "    \"\"\"\n",
    "    # This is a mock implementation - returns random embeddings\n",
    "    return np.random.random((len(texts), 768))\n",
    "\n",
    "print(\"‚úÖ Configuration functions defined\")\n",
    "print(\"‚ö†Ô∏è  Remember to replace mock functions with real API calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Creation\n",
    "\n",
    "Create some sample data for testing the evaluation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample corpus\n",
    "sample_documents = [\n",
    "    \"Health insurance copayments are fixed amounts you pay for covered services. For example, you might pay $20 for a doctor visit.\",\n",
    "    \"Deductibles are amounts you must pay before your insurance begins to pay. A $1,000 deductible means you pay the first $1,000 of covered services.\",\n",
    "    \"Coinsurance is the percentage you pay after meeting your deductible. With 20% coinsurance, you pay 20% and insurance pays 80%.\",\n",
    "    \"Out-of-pocket maximums limit your yearly costs. Once you reach this limit, insurance pays 100% of covered services.\",\n",
    "    \"Prior authorization requires approval before certain services. Emergency services typically don't require prior authorization.\"\n",
    "]\n",
    "\n",
    "# Save sample corpus\n",
    "corpus_df = pd.DataFrame({\n",
    "    'doc_id': [f'doc_{i}' for i in range(len(sample_documents))],\n",
    "    'text': sample_documents,\n",
    "    'source': ['sample'] * len(sample_documents)\n",
    "})\n",
    "\n",
    "loader = DataLoader(base_path='..')\n",
    "loader.save_corpus(corpus_df, 'data/corpus.parquet')\n",
    "\n",
    "print(f\"‚úÖ Created sample corpus with {len(sample_documents)} documents\")\n",
    "print(\"üìÑ Saved to data/corpus.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample evaluation tasks\n",
    "sample_tasks = [\n",
    "    {\n",
    "        \"example_id\": \"task_001\",\n",
    "        \"question\": \"What is a copayment in health insurance?\",\n",
    "        \"reference_answer\": \"A copayment is a fixed amount you pay for covered services, such as $20 for a doctor visit.\",\n",
    "        \"ground_truth_chunk_ids\": [\"chunk_0\"],\n",
    "        \"beir_failure_scale_factor\": 1.0\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"task_002\", \n",
    "        \"question\": \"How does a deductible work?\",\n",
    "        \"reference_answer\": \"A deductible is an amount you must pay before insurance begins to pay. For example, with a $1,000 deductible, you pay the first $1,000 of covered services.\",\n",
    "        \"ground_truth_chunk_ids\": [\"chunk_1\"],\n",
    "        \"beir_failure_scale_factor\": 1.0\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"task_003\",\n",
    "        \"question\": \"What happens after I reach my out-of-pocket maximum?\",\n",
    "        \"reference_answer\": \"Once you reach your out-of-pocket maximum, insurance pays 100% of covered services for the rest of the year.\",\n",
    "        \"ground_truth_chunk_ids\": [\"chunk_3\"],\n",
    "        \"beir_failure_scale_factor\": 1.0\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save sample tasks\n",
    "loader.save_tasks(sample_tasks, 'data/tasks.jsonl')\n",
    "\n",
    "print(f\"‚úÖ Created {len(sample_tasks)} sample evaluation tasks\")\n",
    "print(\"üìÑ Saved to data/tasks.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Validate that everything is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading data\n",
    "loaded_corpus = loader.load_corpus('data/corpus.parquet')\n",
    "loaded_tasks = loader.load_tasks('data/tasks.jsonl')\n",
    "\n",
    "print(f\"‚úÖ Loaded corpus: {len(loaded_corpus)} documents\")\n",
    "print(f\"‚úÖ Loaded tasks: {len(loaded_tasks)} evaluation examples\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìä Sample corpus:\")\n",
    "print(loaded_corpus.head())\n",
    "\n",
    "print(\"\\nüìä Sample tasks:\")\n",
    "for task in loaded_tasks[:2]:\n",
    "    print(f\"  - {task['example_id']}: {task['question'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic functionality\n",
    "print(\"üß™ Testing basic functions...\")\n",
    "\n",
    "# Test LLM function\n",
    "test_response = example_llm_function(\"Test prompt\", temperature=0.1, max_tokens=50)\n",
    "print(f\"‚úÖ LLM function: {test_response[:50]}...\")\n",
    "\n",
    "# Test embedding function\n",
    "test_embeddings = example_embedding_function([\"test text\", \"another test\"])\n",
    "print(f\"‚úÖ Embedding function: shape {test_embeddings.shape}\")\n",
    "\n",
    "print(\"\\nüéâ Setup complete! Ready for notebook 01_ingest_and_index.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}